{
    "name": "root",
    "gauges": {
        "AgentWalk.Policy.Entropy.mean": {
            "value": 1.4168360233306885,
            "min": 1.4168360233306885,
            "max": 1.4176266193389893,
            "count": 3
        },
        "AgentWalk.Policy.Entropy.sum": {
            "value": 70898.4765625,
            "min": 70852.9765625,
            "max": 72237.2890625,
            "count": 3
        },
        "AgentWalk.Step.mean": {
            "value": 149944.0,
            "min": 49967.0,
            "max": 149944.0,
            "count": 3
        },
        "AgentWalk.Step.sum": {
            "value": 149944.0,
            "min": 49967.0,
            "max": 149944.0,
            "count": 3
        },
        "AgentWalk.Policy.ExtrinsicValueEstimate.mean": {
            "value": 141.95590209960938,
            "min": 40.719669342041016,
            "max": 141.95590209960938,
            "count": 3
        },
        "AgentWalk.Policy.ExtrinsicValueEstimate.sum": {
            "value": 115836.015625,
            "min": 36973.4609375,
            "max": 115836.015625,
            "count": 3
        },
        "AgentWalk.Environment.EpisodeLength.mean": {
            "value": 98.61764705882354,
            "min": 98.61764705882354,
            "max": 102.37956204379562,
            "count": 3
        },
        "AgentWalk.Environment.EpisodeLength.sum": {
            "value": 6706.0,
            "min": 6706.0,
            "max": 32622.0,
            "count": 3
        },
        "AgentWalk.Environment.CumulativeReward.mean": {
            "value": 384.6613161143135,
            "min": 384.6613161143135,
            "max": 413.49654868532934,
            "count": 3
        },
        "AgentWalk.Environment.CumulativeReward.sum": {
            "value": 26156.969495773315,
            "min": 26156.969495773315,
            "max": 132732.39212799072,
            "count": 3
        },
        "AgentWalk.Policy.ExtrinsicReward.mean": {
            "value": 384.6613161143135,
            "min": 384.6613161143135,
            "max": 413.49654868532934,
            "count": 3
        },
        "AgentWalk.Policy.ExtrinsicReward.sum": {
            "value": 26156.969495773315,
            "min": 26156.969495773315,
            "max": 132732.39212799072,
            "count": 3
        },
        "AgentWalk.Losses.PolicyLoss.mean": {
            "value": 0.021469944541652998,
            "min": 0.021469944541652998,
            "max": 0.024996218537756555,
            "count": 3
        },
        "AgentWalk.Losses.PolicyLoss.sum": {
            "value": 0.107349722708265,
            "min": 0.09564902545729032,
            "max": 0.12498109268878277,
            "count": 3
        },
        "AgentWalk.Losses.ValueLoss.mean": {
            "value": 153.74078882853192,
            "min": 153.74078882853192,
            "max": 1408.2945933024089,
            "count": 3
        },
        "AgentWalk.Losses.ValueLoss.sum": {
            "value": 768.7039441426596,
            "min": 768.7039441426596,
            "max": 5633.1783732096355,
            "count": 3
        },
        "AgentWalk.Policy.LearningRate.mean": {
            "value": 0.00022528970490344,
            "min": 0.00022528970490344,
            "max": 0.00028401135532955,
            "count": 3
        },
        "AgentWalk.Policy.LearningRate.sum": {
            "value": 0.0011264485245172,
            "min": 0.0011264485245172,
            "max": 0.0012810648729783998,
            "count": 3
        },
        "AgentWalk.Policy.Epsilon.mean": {
            "value": 0.17509656,
            "min": 0.17509656,
            "max": 0.19467044999999997,
            "count": 3
        },
        "AgentWalk.Policy.Epsilon.sum": {
            "value": 0.8754828000000001,
            "min": 0.7786817999999999,
            "max": 0.9270216000000002,
            "count": 3
        },
        "AgentWalk.Policy.Beta.mean": {
            "value": 0.0037573183440000003,
            "min": 0.0037573183440000003,
            "max": 0.0047340554549999995,
            "count": 3
        },
        "AgentWalk.Policy.Beta.sum": {
            "value": 0.018786591720000002,
            "min": 0.018786591720000002,
            "max": 0.02135837784,
            "count": 3
        },
        "AgentWalk.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "AgentWalk.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1712268286",
        "python_version": "3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Dev\\Unity_ML-Agents\\V3\\Articulation\\MLEnv\\Scripts\\mlagents-learn --run-id=FirstWalk1",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1712268416"
    },
    "total": 129.7378035,
    "count": 1,
    "self": 0.004262500000038472,
    "children": {
        "run_training.setup": {
            "total": 0.022907699999999975,
            "count": 1,
            "self": 0.022907699999999975
        },
        "TrainerController.start_learning": {
            "total": 129.71063329999998,
            "count": 1,
            "self": 0.0655991000000995,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.6872851,
                    "count": 1,
                    "self": 11.6872851
                },
                "TrainerController.advance": {
                    "total": 117.86884079999987,
                    "count": 5034,
                    "self": 0.05685359999969819,
                    "children": {
                        "env_step": {
                            "total": 96.61619440000007,
                            "count": 5034,
                            "self": 92.09583469999961,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 4.482442600000427,
                                    "count": 5034,
                                    "self": 0.19467850000046028,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 4.287764099999967,
                                            "count": 5034,
                                            "self": 0.8846421000000042,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3.4031219999999625,
                                                    "count": 5034,
                                                    "self": 3.4031219999999625
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.037917100000033344,
                                    "count": 5033,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 58.6307616000005,
                                            "count": 5033,
                                            "is_parallel": true,
                                            "self": 30.973015000000515,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00043409999999965976,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001858999999999611,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00024819999999969866,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00024819999999969866
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 27.657312499999982,
                                                    "count": 5033,
                                                    "is_parallel": true,
                                                    "self": 0.6407799999995589,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 1.1696956000001197,
                                                            "count": 5033,
                                                            "is_parallel": true,
                                                            "self": 1.1696956000001197
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 24.181737600000062,
                                                            "count": 5033,
                                                            "is_parallel": true,
                                                            "self": 24.181737600000062
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1.665099300000243,
                                                            "count": 5033,
                                                            "is_parallel": true,
                                                            "self": 0.6758966000003017,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.9892026999999413,
                                                                    "count": 10066,
                                                                    "is_parallel": true,
                                                                    "self": 0.9892026999999413
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 21.195792800000106,
                            "count": 5033,
                            "self": 0.12486500000010636,
                            "children": {
                                "process_trajectory": {
                                    "total": 5.3604116999999825,
                                    "count": 5033,
                                    "self": 5.3604116999999825
                                },
                                "_update_policy": {
                                    "total": 15.710516100000016,
                                    "count": 14,
                                    "self": 9.346026999999992,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 6.364489100000023,
                                            "count": 420,
                                            "self": 6.364489100000023
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.000000034120603e-07,
                    "count": 1,
                    "self": 9.000000034120603e-07
                },
                "TrainerController._save_models": {
                    "total": 0.08890740000001074,
                    "count": 1,
                    "self": 0.00821280000002389,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08069459999998685,
                            "count": 1,
                            "self": 0.08069459999998685
                        }
                    }
                }
            }
        }
    }
}