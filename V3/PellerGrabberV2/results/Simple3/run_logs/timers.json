{
    "name": "root",
    "gauges": {
        "AgentControl.Policy.Entropy.mean": {
            "value": 1.438922643661499,
            "min": 1.4201810359954834,
            "max": 1.4405158758163452,
            "count": 10
        },
        "AgentControl.Policy.Entropy.sum": {
            "value": 71960.5234375,
            "min": 71269.140625,
            "max": 72138.53125,
            "count": 10
        },
        "AgentControl.Step.mean": {
            "value": 499959.0,
            "min": 49939.0,
            "max": 499959.0,
            "count": 10
        },
        "AgentControl.Step.sum": {
            "value": 499959.0,
            "min": 49939.0,
            "max": 499959.0,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.mean": {
            "value": 8.61956787109375,
            "min": -0.41938716173171997,
            "max": 8.65683364868164,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.sum": {
            "value": 16109.9716796875,
            "min": -340.12298583984375,
            "max": 16109.9716796875,
            "count": 10
        },
        "AgentControl.Environment.EpisodeLength.mean": {
            "value": 27.528523489932887,
            "min": 26.196557468073294,
            "max": 647.1692307692308,
            "count": 10
        },
        "AgentControl.Environment.EpisodeLength.sum": {
            "value": 49221.0,
            "min": 38666.0,
            "max": 65160.0,
            "count": 10
        },
        "AgentControl.Environment.CumulativeReward.mean": {
            "value": 10.0,
            "min": 1.4615384615384615,
            "max": 10.0,
            "count": 10
        },
        "AgentControl.Environment.CumulativeReward.sum": {
            "value": 17880.0,
            "min": 95.0,
            "max": 17995.0,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicReward.mean": {
            "value": 10.0,
            "min": 1.4615384615384615,
            "max": 10.0,
            "count": 10
        },
        "AgentControl.Policy.ExtrinsicReward.sum": {
            "value": 17880.0,
            "min": 95.0,
            "max": 17995.0,
            "count": 10
        },
        "AgentControl.Losses.PolicyLoss.mean": {
            "value": 0.026952836387014633,
            "min": 0.021356922850342623,
            "max": 0.027698179902411846,
            "count": 10
        },
        "AgentControl.Losses.PolicyLoss.sum": {
            "value": 0.13476418193507317,
            "min": 0.08542769140137049,
            "max": 0.13849089951205923,
            "count": 10
        },
        "AgentControl.Losses.ValueLoss.mean": {
            "value": 0.24213919242223106,
            "min": 0.1739475006237626,
            "max": 1.44140238682429,
            "count": 10
        },
        "AgentControl.Losses.ValueLoss.sum": {
            "value": 1.2106959621111553,
            "min": 0.6957900024950504,
            "max": 7.20701193412145,
            "count": 10
        },
        "AgentControl.Policy.LearningRate.mean": {
            "value": 1.6672774442439992e-05,
            "min": 1.6672774442439992e-05,
            "max": 0.0002845515051495,
            "count": 10
        },
        "AgentControl.Policy.LearningRate.sum": {
            "value": 8.336387221219996e-05,
            "min": 8.336387221219996e-05,
            "max": 0.0012839970720009996,
            "count": 10
        },
        "AgentControl.Policy.Epsilon.mean": {
            "value": 0.10555756000000001,
            "min": 0.10555756000000001,
            "max": 0.19485049999999998,
            "count": 10
        },
        "AgentControl.Policy.Epsilon.sum": {
            "value": 0.5277878,
            "min": 0.5001976000000001,
            "max": 0.927999,
            "count": 10
        },
        "AgentControl.Policy.Beta.mean": {
            "value": 0.00028732224399999996,
            "min": 0.00028732224399999996,
            "max": 0.00474303995,
            "count": 10
        },
        "AgentControl.Policy.Beta.sum": {
            "value": 0.0014366112199999997,
            "min": 0.0014366112199999997,
            "max": 0.021407150099999998,
            "count": 10
        },
        "AgentControl.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "AgentControl.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1712086425",
        "python_version": "3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Dev\\Unity_ML-Agents\\V2\\MLENV\\Scripts\\mlagents-learn --run-id=Simple3",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1712086677"
    },
    "total": 252.709817,
    "count": 1,
    "self": 0.011120499999975664,
    "children": {
        "run_training.setup": {
            "total": 0.018102399999999852,
            "count": 1,
            "self": 0.018102399999999852
        },
        "TrainerController.start_learning": {
            "total": 252.6805941,
            "count": 1,
            "self": 0.4947293999986755,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.9249161,
                    "count": 1,
                    "self": 9.9249161
                },
                "TrainerController.advance": {
                    "total": 242.22403350000133,
                    "count": 41580,
                    "self": 0.4193386999986046,
                    "children": {
                        "env_step": {
                            "total": 165.56384000000162,
                            "count": 41580,
                            "self": 138.4569651000019,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 26.812214200000305,
                                    "count": 41580,
                                    "self": 1.1480863000020278,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 25.664127899998277,
                                            "count": 33347,
                                            "self": 5.801623599998884,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 19.862504299999394,
                                                    "count": 33347,
                                                    "self": 19.862504299999394
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.2946606999994188,
                                    "count": 41580,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 242.59087349999922,
                                            "count": 41580,
                                            "is_parallel": true,
                                            "self": 130.0221434999999,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00039980000000028326,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00018150000000183297,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002182999999984503,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002182999999984503
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 112.56833019999931,
                                                    "count": 41580,
                                                    "is_parallel": true,
                                                    "self": 2.781853299999014,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.1464634999991485,
                                                            "count": 41580,
                                                            "is_parallel": true,
                                                            "self": 4.1464634999991485
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 97.62276100000209,
                                                            "count": 41580,
                                                            "is_parallel": true,
                                                            "self": 97.62276100000209
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 8.017252399999066,
                                                            "count": 41580,
                                                            "is_parallel": true,
                                                            "self": 4.256374699999473,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 3.760877699999593,
                                                                    "count": 83160,
                                                                    "is_parallel": true,
                                                                    "self": 3.760877699999593
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 76.2408548000011,
                            "count": 41580,
                            "self": 0.7443269999993163,
                            "children": {
                                "process_trajectory": {
                                    "total": 19.8465319000018,
                                    "count": 41580,
                                    "self": 19.791695400001807,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.05483649999999329,
                                            "count": 1,
                                            "self": 0.05483649999999329
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 55.64999589999999,
                                    "count": 48,
                                    "self": 33.39251390000061,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 22.257481999999385,
                                            "count": 1440,
                                            "self": 22.257481999999385
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 4.0000000467443897e-07,
                    "count": 1,
                    "self": 4.0000000467443897e-07
                },
                "TrainerController._save_models": {
                    "total": 0.03691470000001118,
                    "count": 1,
                    "self": 0.005650400000007494,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.031264300000003686,
                            "count": 1,
                            "self": 0.031264300000003686
                        }
                    }
                }
            }
        }
    }
}